{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygFzdLAS1vuO"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Print libraries versions"
      ],
      "metadata": {
        "id": "zLpYsk78ImjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, platform\n",
        "\n",
        "print(\"Python:\", sys.version.split()[0])\n",
        "print(\"Platform:\", platform.platform())\n",
        "\n",
        "# Scientific core\n",
        "import numpy as np, pandas as pd, matplotlib, sklearn\n",
        "print(\"Numpy:\", np.__version__)\n",
        "print(\"Pandas:\", pd.__version__)\n",
        "print(\"Matplotlib:\", matplotlib.__version__)\n",
        "print(\"Scikit-learn:\", sklearn.__version__)\n",
        "\n",
        "# PyTorch stack\n",
        "import torch, torchvision\n",
        "print(\"PyTorch:\", torch.__version__)\n",
        "print(\"Torchvision:\", torchvision.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"CUDA runtime:\", torch.version.cuda)\n",
        "print(\"cuDNN:\", torch.backends.cudnn.version())\n",
        "\n",
        "# Gradient boosting libs\n",
        "try:\n",
        "    import xgboost\n",
        "    print(\"XGBoost:\", xgboost.__version__)\n",
        "except ImportError:\n",
        "    print(\"XGBoost: not installed\")\n",
        "\n",
        "try:\n",
        "    import lightgbm\n",
        "    print(\"LightGBM:\", lightgbm.__version__)\n",
        "except ImportError:\n",
        "    print(\"LightGBM: not installed\")\n",
        "\n",
        "# Transformers\n",
        "try:\n",
        "    import transformers\n",
        "    print(\"Transformers:\", transformers.__version__)\n",
        "except ImportError:\n",
        "    print(\"Transformers: not installed\")\n",
        "\n",
        "# TensorFlow (optional)\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    print(\"TensorFlow:\", tf.__version__)\n",
        "except ImportError:\n",
        "    print(\"TensorFlow: not installed\")\n",
        "\n",
        "# Optional video I/O libs\n",
        "for pkg in [\"decord\", \"av\"]:\n",
        "    try:\n",
        "        mod = __import__(pkg)\n",
        "        print(f\"{pkg}:\", mod.__version__)\n",
        "    except:\n",
        "        pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIpY5NZBk0WZ",
        "outputId": "c08c19b2-2acd-4d99-bde0-bea0daba6470"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python: 3.12.12\n",
            "Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n",
            "Numpy: 2.0.2\n",
            "Pandas: 2.2.2\n",
            "Matplotlib: 3.10.0\n",
            "Scikit-learn: 1.6.1\n",
            "PyTorch: 2.8.0+cu126\n",
            "Torchvision: 0.23.0+cu126\n",
            "CUDA available: True\n",
            "CUDA runtime: 12.6\n",
            "cuDNN: 91002\n",
            "XGBoost: 3.1.1\n",
            "LightGBM: 4.6.0\n",
            "Transformers: 4.57.1\n",
            "TensorFlow: 2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUxv1KvYBROg"
      },
      "source": [
        "## Remove an old code version\n",
        "- if present"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1uXQCCyYJi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9c65b73-6df3-4269-ed48-b66ebf70ac4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'SpecklesAI': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -r SpecklesAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeoBxhqQBWgn"
      },
      "source": [
        "## Clone repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2HMjR5neV53P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b64444bb-38bc-4806-b2d9-e43601b98a5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SpecklesAI'...\n",
            "remote: Enumerating objects: 943, done.\u001b[K\n",
            "remote: Counting objects: 100% (52/52), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 943 (delta 23), reused 0 (delta 0), pack-reused 891 (from 3)\u001b[K\n",
            "Receiving objects: 100% (943/943), 15.00 MiB | 10.21 MiB/s, done.\n",
            "Resolving deltas: 100% (491/491), done.\n"
          ]
        }
      ],
      "source": [
        "#if you are clonning a public version, use:\n",
        "!git clone https://github.com/natalyasegal/SpecklesAI.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy config.py (for Broca area)"
      ],
      "metadata": {
        "id": "ZF91c7gMI_pX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp SpecklesAI/config/config_BCI.py SpecklesAI/config/config.py"
      ],
      "metadata": {
        "id": "M2kzh33VJCUv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import functions that will be used directly"
      ],
      "metadata": {
        "id": "-JOao7xaJVSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/SpecklesAI')   # add package root to Python path\n",
        "\n",
        "#from utils.swap import swap_categories\n",
        "from utils.swap import *"
      ],
      "metadata": {
        "id": "SMya4py5JaR7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jrxiKoKDBnSa"
      },
      "source": [
        "# Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0-DYgwWlGOyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b24fc837-f271-44ca-fea1-4aebd306ad4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLR0KhtGBoxN"
      },
      "source": [
        "## Copy cofiguration files\n",
        "- add here code that copies your actual configuartion files with subjects and dates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDDFkY-CCBHK"
      },
      "source": [
        "#Dataset - speckle video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tGY4_J6CsAe"
      },
      "source": [
        "### Remove old data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E2wHHtyCzzV"
      },
      "source": [
        "Run this only if you have created this directory before in the same runtime and need to recreate it differently"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZOPa5kvCly-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7923152f-15ec-4028-8edd-9a5ba1a0f87b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'exp3': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -r exp3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyV365ZaDJap"
      },
      "source": [
        "### Unzip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip gdrive/My\\ Drive/__PHd_2025/code_and_data/data_BCI/your_file_name.zip\n",
        "# add here more data files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptqAx-Jm1VDD",
        "outputId": "ee110599-ae73-44ae-bff0-4437eab427dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  gdrive/My Drive/__PHd_2025/code_and_data/data_BCI/BCI_Adi_9June25_forehead.zip\n",
            "   creating: BCI_Adi_9June25_forehead/\n",
            "   creating: BCI_Adi_9June25_forehead/090625_day1_1/\n",
            "   creating: BCI_Adi_9June25_forehead/090625_day1_1/Adi/\n",
            "   creating: BCI_Adi_9June25_forehead/090625_day1_1/Adi/forehead/\n",
            "   creating: BCI_Adi_9June25_forehead/090625_day1_1/Adi/forehead/no/\n",
            "  inflating: BCI_Adi_9June25_forehead/090625_day1_1/Adi/forehead/no/acA1440-220um__40034984__20250609_113919482.avi  \n",
            "  inflating: BCI_Adi_9June25_forehead/090625_day1_1/Adi/forehead/no/acA1440-220um__40034984__20250609_113950238.avi  \n",
            "  inflating: BCI_Adi_9June25_forehead/090625_day1_1/Adi/forehead/no/acA1440-220um__40034984__20250609_114020231.avi  \n",
            "  inflating: BCI_Adi_9June25_forehead/090625_day1_1/Adi/forehead/no/acA1440-220um__40034984__20250609_114359069.avi  \n",
            "  inflating: BCI_Adi_9June25_forehead/090625_day1_1/Adi/forehead/no/acA1440-220um__40034984__20250609_114431310.avi  \n",
            "   creating: BCI_Adi_9June25_forehead/090625_day1_1/Adi/forehead/yes/\n",
            "  inflating: BCI_Adi_9June25_forehead/090625_day1_1/Adi/forehead/yes/acA1440-220um__40034984__20250609_113646333.avi  \n",
            "  inflating: BCI_Adi_9June25_forehead/090625_day1_1/Adi/forehead/yes/acA1440-220um__40034984__20250609_113716089.avi  \n",
            "  inflating: BCI_Adi_9June25_forehead/090625_day1_1/Adi/forehead/yes/acA1440-220um__40034984__20250609_113746435.avi  \n",
            "  inflating: BCI_Adi_9June25_forehead/090625_day1_1/Adi/forehead/yes/acA1440-220um__40034984__20250609_113816633.avi  \n",
            "  inflating: BCI_Adi_9June25_forehead/090625_day1_1/Adi/forehead/yes/acA1440-220um__40034984__20250609_113847308.avi  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxwPcGNnDSVr"
      },
      "source": [
        "### Move\n",
        "- add here moving the data to exp3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir exp3\n",
        "# move here ..."
      ],
      "metadata": {
        "id": "zRKpcxW-H3QH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls exp3/"
      ],
      "metadata": {
        "id": "_L9AjK_S9xbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample path structure you will get:\n",
        "!ls exp3/090625_day1_1/SubjNameOrCode/Broca/yes\n",
        "#!ls exp3/090625_day1_1/SubjNameOrCode/Broca/no"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEtHiRTQ7Huc",
        "outputId": "ad4eddfe-9138-46fd-c9aa-e213d5a774a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acA1440-220um__40034984__20250609_143942792.avi\n",
            "acA1440-220um__40034984__20250609_144012680.avi\n",
            "acA1440-220um__40034984__20250609_144042863.avi\n",
            "acA1440-220um__40034984__20250609_144112971.avi\n",
            "acA1440-220um__40034984__20250609_144145530.avi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHmUKrStywfk"
      },
      "source": [
        "# Create per subject test datasets\n",
        "- for morning/midday/forehead, dataset is chused during unzip/move satage\n",
        "- changing directory name to Broca just for simplicity in case of forehead as well\n",
        "- changing directory mame to 1_1 at the end for simplicity in case of morning set, in order to use the test creation code as is"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create for SampleSubj"
      ],
      "metadata": {
        "id": "29iYU5eV9P4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### copy config"
      ],
      "metadata": {
        "id": "whLvrEKGIIrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r gdrive/MyDrive/your_input_config_location/subjects_and_dates_Zeev__2__only.yaml SpecklesAI/config/config_files/subjects_and_dates.yaml\n",
        "!cat SpecklesAI/config/config_files/subjects_and_dates.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vulVojZVEMKw",
        "outputId": "0d535595-6a11-4838-d029-8647735a1ce1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#subjects_and_dates.yaml\r\n",
            "\r\n",
            "subjects:\r\n",
            "  1: \r\n",
            "    dates: ['090625_day1', '090625_day1_1']\r\n",
            "    name: 'Zeev'\r\n",
            "  "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### create"
      ],
      "metadata": {
        "id": "AEC0ULLQILM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -u SpecklesAI/prepare_test_sets.py --split_num 1 --random_seed 9  --test_set_per_category_file test_per_category_BCI_forehead__\n",
        "!mv test_per_category_BCI_forehead___1.npy test_per_category_BCI_forehead___5_2.npy\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDGnQAG9D6tW",
        "outputId": "ad13790d-34e8-47b4-b6a1-a48ffe4a2a1f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " number_of_classes = 2\n",
            " binary_lables=[[0]\n",
            " [1]]\n",
            "Splits list:\n",
            "{1: {'test_mix': [1], 'model_name': 'AYYZDS_mix_1'}, 2: {'test_mix': [2], 'model_name': 'AYYZDS_mix_2'}, 3: {'test_mix': [3], 'model_name': 'AYYZDS_mix_3'}, 4: {'test_mix': [4], 'model_name': 'AYYZDS_mix_4'}, 5: {'test_mix': [5], 'model_name': 'AYYZDS_mix_5'}, 6: {'test_mix': [6], 'model_name': 'AYYZDS_mix_6'}, 7: {'test_mix': [7], 'model_name': 'AYYZDS_mix_7'}, 8: {'test_mix': [8], 'model_name': 'AYYZDS_mix_8'}, 9: {'test_mix': [7, 8], 'model_name': 'AYYZDS_mix_9'}}\n",
            "The chosen split number is 1, test: [1], AYYZDS_mix_1\n",
            " subject number = 1, name = ['Zeev'],  dates=['090625_day1_1'] \n",
            " test {'090625_day1_1'} {'Zeev'}\n",
            " number_of_classes = 2\n",
            " binary_lables=[[0]\n",
            " [1]]\n",
            "Splits list:\n",
            "{1: {'test_mix': [1], 'model_name': 'AYYZDS_mix_1'}, 2: {'test_mix': [2], 'model_name': 'AYYZDS_mix_2'}, 3: {'test_mix': [3], 'model_name': 'AYYZDS_mix_3'}, 4: {'test_mix': [4], 'model_name': 'AYYZDS_mix_4'}, 5: {'test_mix': [5], 'model_name': 'AYYZDS_mix_5'}, 6: {'test_mix': [6], 'model_name': 'AYYZDS_mix_6'}, 7: {'test_mix': [7], 'model_name': 'AYYZDS_mix_7'}, 8: {'test_mix': [8], 'model_name': 'AYYZDS_mix_8'}, 9: {'test_mix': [7, 8], 'model_name': 'AYYZDS_mix_9'}}\n",
            "The chosen split number is 1, test: [1], AYYZDS_mix_1\n",
            " subject number = 1, name = ['Zeev'],  dates=['090625_day1_1'] \n",
            " test {'090625_day1_1'} {'Zeev'}\n",
            "handle_one_split: split_num = <function handle_one_split at 0x7e6f158c8a40>.\n",
            "=======\n",
            "Processing: test\n",
            "=======\n",
            "['data/test/Zeev/b/yes', 'data/test/Zeev/b/no']\n",
            "Input: exp3/090625_day1_1/Zeev/Broca/yes, Output: data/test/Zeev/b/yes\n",
            "  0% 0/5 [00:00<?, ?it/s]--- data/test/Zeev/b/yes   exp3/090625_day1_1/Zeev/Broca/yes/acA1440-220um__40034984__20250609_144145530.avi\n",
            "\u001b[0;36m[rawvideo @ 0x2a2acd40] \u001b[0m\u001b[1;31mPacket too small (16)\n",
            " 20% 1/5 [00:04<00:19,  4.91s/it]--- data/test/Zeev/b/yes   exp3/090625_day1_1/Zeev/Broca/yes/acA1440-220um__40034984__20250609_144112971.avi\n",
            "\u001b[0;36m[rawvideo @ 0x2a2b39c0] \u001b[0m\u001b[1;31mPacket too small (16)\n",
            " 40% 2/5 [00:09<00:13,  4.49s/it]--- data/test/Zeev/b/yes   exp3/090625_day1_1/Zeev/Broca/yes/acA1440-220um__40034984__20250609_144042863.avi\n",
            "\u001b[0;36m[rawvideo @ 0x2a3dadc0] \u001b[0m\u001b[1;31mPacket too small (16)\n",
            " 60% 3/5 [00:12<00:08,  4.18s/it]--- data/test/Zeev/b/yes   exp3/090625_day1_1/Zeev/Broca/yes/acA1440-220um__40034984__20250609_143942792.avi\n",
            "\u001b[0;36m[rawvideo @ 0x2a3dc6c0] \u001b[0m\u001b[1;31mPacket too small (16)\n",
            " 80% 4/5 [00:16<00:04,  4.12s/it]--- data/test/Zeev/b/yes   exp3/090625_day1_1/Zeev/Broca/yes/acA1440-220um__40034984__20250609_144012680.avi\n",
            "\u001b[0;36m[rawvideo @ 0x2a3dc6c0] \u001b[0m\u001b[1;31mPacket too small (16)\n",
            "100% 5/5 [00:21<00:00,  4.35s/it]\n",
            "Input: exp3/090625_day1_1/Zeev/Broca/no, Output: data/test/Zeev/b/no\n",
            "  0% 0/5 [00:00<?, ?it/s]--- data/test/Zeev/b/no   exp3/090625_day1_1/Zeev/Broca/no/acA1440-220um__40034984__20250609_144251022.avi\n",
            "\u001b[0;36m[rawvideo @ 0x2a2b0840] \u001b[0m\u001b[1;31mPacket too small (16)\n",
            " 20% 1/5 [00:04<00:16,  4.08s/it]--- data/test/Zeev/b/no   exp3/090625_day1_1/Zeev/Broca/no/acA1440-220um__40034984__20250609_144352349.avi\n",
            "\u001b[0;36m[rawvideo @ 0x2a2b03c0] \u001b[0m\u001b[1;31mPacket too small (16)\n",
            " 40% 2/5 [00:08<00:12,  4.01s/it]--- data/test/Zeev/b/no   exp3/090625_day1_1/Zeev/Broca/no/acA1440-220um__40034984__20250609_144321428.avi\n",
            "\u001b[0;36m[rawvideo @ 0x2a3e9840] \u001b[0m\u001b[1;31mPacket too small (16)\n",
            " 60% 3/5 [00:13<00:08,  4.50s/it]--- data/test/Zeev/b/no   exp3/090625_day1_1/Zeev/Broca/no/acA1440-220um__40034984__20250609_144221107.avi\n",
            "\u001b[0;36m[rawvideo @ 0x2a339100] \u001b[0m\u001b[1;31mPacket too small (16)\n",
            " 80% 4/5 [00:17<00:04,  4.33s/it]--- data/test/Zeev/b/no   exp3/090625_day1_1/Zeev/Broca/no/acA1440-220um__40034984__20250609_144423277.avi\n",
            "\u001b[0;36m[rawvideo @ 0x2a3e9840] \u001b[0m\u001b[1;31mPacket too small (16)\n",
            "100% 5/5 [00:21<00:00,  4.30s/it]\n",
            "test True \n",
            "['data/test/Zeev/b/yes', 'data/test/Zeev/b/no']\n",
            "100% 100005/100005 [00:06<00:00, 15067.17it/s]\n",
            "index = 0 len = 2500\n",
            "100% 100005/100005 [00:05<00:00, 19299.53it/s]\n",
            "index = 1 len = 2500\n",
            "shape of the data (2, 2500, 40, 32, 32, 1)\n",
            "max_chanks=100000\n",
            "actual_len = 2\n",
            " x[0] shape is (2500, 40, 32, 32, 1)\n",
            " x[1] shape is (2500, 40, 32, 32, 1)\n",
            "x_test shape is (5000, 40, 32, 32, 1), y_test shape is (5000, 1)\n",
            "Saving test_per_category_BCI_forehead___1.npy\n",
            "BCI_Adi_9June25_forehead\n",
            "BCI_Dima_280425_morning_forehead\n",
            "BCI_Dolev_250225_midday_forehead\n",
            "BCI_Dolev_250225_morning_forehead\n",
            "BCI_Efrat_4June25_forehead\n",
            "BCI_Eithan_7May2025_morning_forehead\n",
            "BCI_Natalya_4June25_forehead\n",
            "BCI_rightside_27May25_Rotem_midday__forehead\n",
            "BCI_Sergey\n",
            "BCI_Yafim\n",
            "BCI_Zeev_9June25_forehead\n",
            "data\n",
            "exp3\n",
            "gdrive\n",
            "sample_data\n",
            "SpecklesAI\n",
            "test_per_category_BCI_forehead___5_2.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### save"
      ],
      "metadata": {
        "id": "gLEBuTqfGNzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir gdrive/MyDrive/your_location\n",
        "!cp test_per_category_BCI_forehead___5_2.npy\tgdrive/MyDrive/your_location/.\n",
        "!ls -l gdrive/MyDrive/your_location"
      ],
      "metadata": {
        "id": "il_f-e-ZGPBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test forehead\n",
        "- on per subj models that were trained/validated on the morning set and tested on midday set of the same subject"
      ],
      "metadata": {
        "id": "SOM7HKkSpOS9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## copy test sets"
      ],
      "metadata": {
        "id": "RPnDz2sqpkzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp gdrive/MyDrive/ypur_location/*.npy .\n",
        "!ls -l *.npy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjIAJMDNpSOu",
        "outputId": "43850685-49f5-4fe4-eed2-29252fa59a1f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 204800128 Nov 21 10:57 test_per_category_BCI_forehead___10.npy\n",
            "-rw------- 1 root root 122880128 Nov 21 10:57 test_per_category_BCI_forehead___1.npy\n",
            "-rw------- 1 root root 122880128 Nov 21 10:57 test_per_category_BCI_forehead___1_swapped.npy\n",
            "-rw------- 1 root root 122880128 Nov 21 10:57 test_per_category_BCI_forehead___2.npy\n",
            "-rw------- 1 root root 204800128 Nov 21 10:57 test_per_category_BCI_forehead___3.npy\n",
            "-rw------- 1 root root 122880128 Nov 21 10:57 test_per_category_BCI_forehead___4.npy\n",
            "-rw------- 1 root root 204800128 Nov 21 10:58 test_per_category_BCI_forehead___5_2.npy\n",
            "-rw------- 1 root root 122880128 Nov 21 10:58 test_per_category_BCI_forehead___5.npy\n",
            "-rw------- 1 root root 245760128 Nov 21 10:58 test_per_category_BCI_forehead___6.npy\n",
            "-rw------- 1 root root 204800128 Nov 21 10:58 test_per_category_BCI_forehead___7_2.npy\n",
            "-rw------- 1 root root 204800128 Nov 21 10:58 test_per_category_BCI_forehead___7.npy\n",
            "-rw------- 1 root root 204800128 Nov 21 10:59 test_per_category_BCI_forehead___8.npy\n",
            "-rw------- 1 root root 204800128 Nov 21 10:59 test_per_category_BCI_forehead___8_swapped.npy\n",
            "-rw------- 1 root root 204800128 Nov 21 10:59 test_per_category_BCI_forehead___9.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sample subject"
      ],
      "metadata": {
        "id": "kWUZND1NqUy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r gdrive/MyDrive/your_path/pBCI_models_per_subj/per_subj_split_3/models .\n",
        "\n",
        "# 25 chunks (40 frames in chunk, taken eith 1000 fps) correspond to 1 second of input\n",
        "!python -u SpecklesAI/inference_and_eval.py --use_per_subj_config --num_of_chunks_to_aggregate 25 --read_stored_dataset  --test_set_per_category_file test_per_category_BCI_forehead___3.npy --split_num 1 #patch giving meaningless split number here\n",
        "\n",
        "!mkdir gdrive/MyDrive/your_path/pBCI_control__test_forehead_per_subj/per_subj_3_25\n",
        "!mv models gdrive/MyDrive/your_path/pBCI_control__test_forehead_per_subj/per_subj_3_25/.\n",
        "!mv *.png gdrive/MyDrive/your_path/pBCI_control__test_forehead_per_subj/per_subj_3_25/.\n",
        "!mv *.csv gdrive/MyDrive/your_path/pBCI_control__test_forehead_per_subj/per_subj_3_25/.\n",
        "!ls -l gdrive/MyDrive/your_path/pBCI_control__test_forehead_per_subj/per_subj_3_25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UKOvQORPUG1",
        "outputId": "222ae4c7-58d4-4cdc-a374-de235f9f368c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-11-19 13:15:14.171955: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1763558114.186546   19007 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1763558114.190720   19007 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1763558114.201762   19007 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763558114.201806   19007 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763558114.201808   19007 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1763558114.201810   19007 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-19 13:15:14.205246: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            " number_of_classes = 2\n",
            " binary_lables=[[0]\n",
            " [1]]\n",
            "The chosen split number (=subj number) is 1\n",
            " subject number = 1, name = ['SubjectOneName'],  dates=['somedate_day1'] \n",
            " subject number = 1, name = ['SubjectOneName'],  dates=['somedate_day1_1'] \n",
            " train {'somedate_day1'} {'SubjectOneName'}\n",
            " val [] [1]\n",
            " test {'somedate_day1_1'} {'SubjectOneName'}\n",
            "Loading test_per_category_BCI_forehead___3.npy\n",
            "max_chanks=100000\n",
            "actual_len = 2\n",
            " x[0] shape is (2500, 40, 32, 32, 1)\n",
            " x[1] shape is (2500, 40, 32, 32, 1)\n",
            "Displaying sample frames 235.\n",
            "Figure(900x800)\n",
            "x_test shape: (5000, 40, 32, 32, 1)\n",
            "y_test shape: (5000, 1)\n",
            "x_test_per_category shape: (2, 2500, 40, 32, 32, 1)\n",
            "model path is  models\n",
            "Loading model from models/best_model.keras as a Keras file.\n",
            "2025-11-19 13:15:18.638845: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "Model Input Shape: (500, 40, 32, 32, 1)\n",
            "Model Output Shape: (500, 1)\n",
            "2025-11-19 13:15:19.140654: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 244ms/step\n",
            "y_test shape: (5000, 1)\n",
            "y_test_predicted shape: (5000, 1)\n",
            "The chosen(using AUC-ROC curve) optimal threshold is 0.0009196908213198185\n",
            "Results saved to Subj_experiment_model_per_chunk.csv\n",
            "Confusion matrix, without normalization\n",
            "[[2380  120]\n",
            " [  94 2406]]\n",
            "Figure(640x480)\n",
            "Normalized confusion matrix\n",
            "[[0.95 0.05]\n",
            " [0.04 0.96]]\n",
            "Figure(640x480)\n",
            "Figure(1000x600)\n",
            "                      Model Name       AUC  ...  Cohen Kappa  Threshold\n",
            "0  Subj_experiment_model_split_1  0.989961  ...       0.9144    0.00092\n",
            "\n",
            "[1 rows x 6 columns]\n",
            "2025-11-19 13:15:58.478193: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 232ms/step\n",
            "2025-11-19 13:16:16.978906: E tensorflow/core/framework/node_def_util.cc:680] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 235ms/step\n",
            "max_chunks_num =2500 max_iterations =100, len of accumulated predictions 100\n",
            "max_chunks_num =2500 max_iterations =100, len of accumulated predictions 100\n",
            " auc = 1.0, on 200 values from 2 categories\n",
            "(200,)\n",
            "(200,)\n",
            "The chosen(using AUC-ROC curve) optimal threshold for aggregated chunks is 0.0011832151794806123\n",
            "Results saved to Subj_experiment_model_aggregated.csv\n",
            "Confusion matrix, without normalization\n",
            "[[100   0]\n",
            " [  1  99]]\n",
            "Normalized confusion matrix\n",
            "[[1.   0.  ]\n",
            " [0.01 0.99]]\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(1000x600)\n",
            "Accumulated metrics:\n",
            "                      Model Name  AUC  ...  Cohen Kappa  Threshold\n",
            "0  Subj_experiment_model_split_1  1.0  ...         0.99   0.001183\n",
            "\n",
            "[1 rows x 6 columns]\n",
            "total 176\n",
            "-rw-------+ 1 root root 16856 Nov 19 13:16 confusion_matrix_agg.png\n",
            "-rw-------+ 1 root root 17823 Nov 19 13:15 confusion_matrix.png\n",
            "drwx------+ 2 root root  4096 Nov 19 13:11 models\n",
            "-rw-------+ 1 root root 35114 Nov 19 13:16 roc_curve_agg.png\n",
            "-rw-------+ 1 root root 37255 Nov 19 13:15 roc_curve.png\n",
            "-rw-------+ 1 root root 66999 Nov 19 13:15 speckles_sample.png\n",
            "-rw-------+ 1 root root   132 Nov 19 13:16 Subj_experiment_model_aggregated.csv\n",
            "-rw-------+ 1 root root   142 Nov 19 13:15 Subj_experiment_model_per_chunk.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensembled Inference"
      ],
      "metadata": {
        "id": "FZfBj7yI7jD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### copy datasets - midday"
      ],
      "metadata": {
        "id": "vlO4irCyMTWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp gdrive/MyDrive/your_path/data_exp3_prep_BCI/per_subj_splits/test_per_category__per_subj___2_no_beep.npy .\n",
        "!cp gdrive/MyDrive/your_path/data_exp3_prep_BCI/per_subj_splits/test_per_category__per_subj__2.npy .\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z5IMUFcZIVw",
        "outputId": "188a0f29-2054-4d09-c8eb-b2ba2d01bcc1",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\t\t\t\t\t     train_set__per_subj__1.npy\n",
            "sample_data\t\t\t\t     train_set__per_subj__3.npy\n",
            "SpecklesAI\t\t\t\t     train_set__per_subj__4.npy\n",
            "test_per_category__per_subj__1.npy\t     train_set__per_subj__5.npy\n",
            "test_per_category__per_subj___2_no_beep.npy  validation_set__per_subj__1.npy\n",
            "test_per_category__per_subj__2.npy\t     validation_set__per_subj__3.npy\n",
            "test_per_category__per_subj__3.npy\t     validation_set__per_subj__4.npy\n",
            "test_per_category__per_subj__4.npy\t     validation_set__per_subj__5.npy\n",
            "test_per_category__per_subj__5.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To copy preprecessed datasets for the current split run:\n",
        "!cp gdrive/MyDrive/your_path/data_exp3_prep_BCI/per_subj_splits/*_1.npy .\n",
        "#!cp gdrive/MyDrive/your_path/data_exp3_prep_BCI/per_subj_splits/*_2.npy .\n",
        "!cp gdrive/MyDrive/your_path/data_exp3_prep_BCI/per_subj_splits/*_3.npy .\n",
        "!cp gdrive/MyDrive/your_path/data_exp3_prep_BCI/per_subj_splits/*_4.npy .\n",
        "!cp gdrive/MyDrive/your_path/data_exp3_prep_BCI/per_subj_splits/*_5.npy .\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxujXS_tMTj5",
        "outputId": "d5967f3b-ab6b-4ced-97da-c8748eaacbca",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\t\t\t\t    train_set__per_subj__3.npy\n",
            "sample_data\t\t\t    train_set__per_subj__4.npy\n",
            "SpecklesAI\t\t\t    train_set__per_subj__5.npy\n",
            "test_per_category__per_subj__1.npy  validation_set__per_subj__1.npy\n",
            "test_per_category__per_subj__3.npy  validation_set__per_subj__3.npy\n",
            "test_per_category__per_subj__4.npy  validation_set__per_subj__4.npy\n",
            "test_per_category__per_subj__5.npy  validation_set__per_subj__5.npy\n",
            "train_set__per_subj__1.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## subj 2 in **test**\n",
        "- example on 8 models minus 1 (of the subj on test)"
      ],
      "metadata": {
        "id": "_6N12x4MpYfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r all_models\n",
        "!mkdir all_models\n",
        "!cp -r gdrive/MyDrive/your_path/pBCI_models_per_subj/per_subj_split_1/models all_models/models_1\n",
        "#!cp -r gdrive/MyDrive/your_path/pBCI_models_per_subj/per_subj_split__2_no_beep/models all_models/models_2\n",
        "!cp -r gdrive/MyDrive/your_path/pBCI_models_per_subj/per_subj_split_3/models all_models/models_3\n",
        "!cp -r gdrive/MyDrive/your_path/pBCI_models_per_subj/per_subj_split_4/models all_models/models_4\n",
        "!cp -r gdrive/MyDrive/your_path/pBCI_models_per_subj/per_subj_split_5/models all_models/models_5\n",
        "!cp -r gdrive/MyDrive/your_path/pBCI_models_per_subj/per_subj_split_6/models all_models/models_6\n",
        "!cp -r gdrive/MyDrive/your_path/pBCI_models_per_subj/per_subj_split_7/models all_models/models_7\n",
        "!cp -r gdrive/MyDrive/your_path/pBCI_models_per_subj/per_subj_split_8/models all_models/models_8\n",
        "!ls all_models\n",
        "\n",
        "#50 as there is a word every 2 sec in version of data with beep\n",
        "!cp gdrive/MyDrive/your_path/data_exp3_prep_BCI/per_subj_splits/test_per_category__per_subj__2.npy .\n",
        "\n",
        "!python -u SpecklesAI/inference_and_eval.py  --need_ensemble --use_per_subj_config --num_of_chunks_to_aggregate 50 --read_stored_dataset  --test_set_per_category_file test_per_category__per_subj__2.npy --split_num 1 #patch giving meaningless split number here"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWemGEk_pZ7r",
        "outputId": "e836460c-4b91-4066-d7d5-a5d6ad9f0c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models_1  models_3  models_4  models_5\tmodels_6  models_7  models_8\n",
            "2025-05-25 13:36:34.182220: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-25 13:36:34.200938: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748180194.221669   45836 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748180194.228056   45836 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-25 13:36:34.249003: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            " number_of_classes = 2\n",
            " binary_lables=[[0]\n",
            " [1]]\n",
            "The chosen split number (=subj number) is 1\n",
            " subject number = 1, name = ['Zeev'],  dates=['310325_day1'] \n",
            " subject number = 1, name = ['Zeev'],  dates=['310325_day1_1'] \n",
            " train {'310325_day1'} {'Zeev'}\n",
            " val [] [1]\n",
            " test {'310325_day1_1'} {'Zeev'}\n",
            "Loading test_per_category__per_subj__2.npy\n",
            "max_chanks=100000\n",
            " x[0] shape is (2500, 40, 32, 32, 1)\n",
            " x[1] shape is (2500, 40, 32, 32, 1)\n",
            "Displaying sample frames 235.\n",
            "Figure(900x800)\n",
            "x_test shape: (5000, 40, 32, 32, 1)\n",
            "y_test shape: (5000, 1)\n",
            "x_test_per_category shape: (2, 2500, 40, 32, 32, 1)\n",
            "models_1\n",
            "models_7\n",
            "models_6\n",
            "models_8\n",
            "models_5\n",
            "models_4\n",
            "models_3\n",
            "Subdirectories: ['all_models/models_1', 'all_models/models_7', 'all_models/models_6', 'all_models/models_8', 'all_models/models_5', 'all_models/models_4', 'all_models/models_3']\n",
            "model path is  all_models/models_1\n",
            "Loading model from all_models/models_1/best_model.keras as a Keras file.\n",
            "2025-05-25 13:36:37.710425: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1748180197.710569   45836 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38546 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
            "Model Input Shape: (500, 40, 32, 32, 1)\n",
            "Model Output Shape: (500, 1)\n",
            "model path is  all_models/models_7\n",
            "Loading model from all_models/models_7/best_model.keras as a Keras file.\n",
            "Model Input Shape: (None, 40, 32, 32, 1)\n",
            "Model Output Shape: (None, 1)\n",
            "model path is  all_models/models_6\n",
            "Loading model from all_models/models_6/best_model.keras as a Keras file.\n",
            "Model Input Shape: (None, 40, 32, 32, 1)\n",
            "Model Output Shape: (None, 1)\n",
            "model path is  all_models/models_8\n",
            "Loading model from all_models/models_8/best_model.keras as a Keras file.\n",
            "Model Input Shape: (None, 40, 32, 32, 1)\n",
            "Model Output Shape: (None, 1)\n",
            "model path is  all_models/models_5\n",
            "Loading model from all_models/models_5/best_model.keras as a Keras file.\n",
            "Model Input Shape: (None, 40, 32, 32, 1)\n",
            "Model Output Shape: (None, 1)\n",
            "model path is  all_models/models_4\n",
            "Loading model from all_models/models_4/best_model.keras as a Keras file.\n",
            "Model Input Shape: (1000, 40, 32, 32, 1)\n",
            "Model Output Shape: (1000, 1)\n",
            "model path is  all_models/models_3\n",
            "Loading model from all_models/models_3/best_model.keras as a Keras file.\n",
            "Model Input Shape: (500, 40, 32, 32, 1)\n",
            "Model Output Shape: (500, 1)\n",
            "2025-05-25 13:36:40.222964: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
            "I0000 00:00:1748180200.918972   45921 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step\n",
            "2025-05-25 13:36:46.361103: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step\n",
            "2025-05-25 13:36:51.636578: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step\n",
            "2025-05-25 13:36:57.027065: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step\n",
            "2025-05-25 13:37:02.288467: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step\n",
            "2025-05-25 13:37:07.683981: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step\n",
            "2025-05-25 13:37:12.874426: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step\n",
            "Evaluating 7 models...\n",
            "y_test shape: (5000, 1)\n",
            "Model 1: Optimal threshold (using AUC-ROC curve) = 0.9550\n",
            "Model 2: Optimal threshold (using AUC-ROC curve) = 0.9984\n",
            "Model 3: Optimal threshold (using AUC-ROC curve) = 0.9079\n",
            "Model 4: Optimal threshold (using AUC-ROC curve) = 0.5441\n",
            "Model 5: Optimal threshold (using AUC-ROC curve) = 0.9588\n",
            "Model 6: Optimal threshold (using AUC-ROC curve) = 0.8407\n",
            "Model 7: Optimal threshold (using AUC-ROC curve) = 0.0016\n",
            "Results saved to ensemble_of_7_models.csv\n",
            "Confusion matrix, without normalization\n",
            "[[2500    0]\n",
            " [  14 2486]]\n",
            "Figure(640x480)\n",
            "Normalized confusion matrix\n",
            "[[1.   0.  ]\n",
            " [0.01 0.99]]\n",
            "Figure(640x480)\n",
            "Figure(1000x600)\n",
            "  Model Name       AUC  Accuracy  F1 Score  Cohen Kappa  Threshold\n",
            "0   ensemble  0.999994    0.9972  0.997192       0.9944   0.001628\n",
            "2025-05-25 13:37:18.566516: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
            "2025-05-25 13:37:25.910449: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
            "2025-05-25 13:37:33.199396: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
            "2025-05-25 13:37:40.563027: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
            "2025-05-25 13:37:47.881867: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
            "max_chunks_num =2500 max_iterations =100, len of accumulated predictions 100\n",
            "max_chunks_num =2500 max_iterations =100, len of accumulated predictions 100\n",
            " auc = 1.0, on 200 values from 2 categories\n",
            "(200,)\n",
            "(200,)\n",
            "The chosen(using AUC-ROC curve) optimal threshold for aggregated chunks is 0.73797208070755\n",
            "Results saved to Subj_experiment_model_aggregated.csv\n",
            "Confusion matrix, without normalization\n",
            "[[100   0]\n",
            " [  1  99]]\n",
            "Normalized confusion matrix\n",
            "[[1.   0.  ]\n",
            " [0.01 0.99]]\n",
            "Figure(640x480)\n",
            "Figure(640x480)\n",
            "Figure(1000x600)\n",
            "Figure(1600x800)\n",
            "Accumulated metrics:\n",
            "                      Model Name  AUC  ...  Cohen Kappa  Threshold\n",
            "0  Subj_experiment_model_split_1  1.0  ...         0.99   0.737972\n",
            "\n",
            "[1 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "toJuJdDwKMOM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## different subject\n",
        "- test per subject models to see how they perform on another subject"
      ],
      "metadata": {
        "id": "Q52ejLCL-2cT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### copy datasets"
      ],
      "metadata": {
        "id": "eHONarkLMMd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To copy preprocessed datasets for the current split run:\n",
        "!cp gdrive/your_path/data_exp3_prep_BCI/per_subj_splits/*_*.npy .\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYrwUi4l-6RO",
        "outputId": "e4fc277e-046b-4fc1-a143-0ecacf668e75",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\t\t\t\t    train_set__per_subj__3.npy\n",
            "sample_data\t\t\t    train_set__per_subj__4.npy\n",
            "SpecklesAI\t\t\t    train_set__per_subj__5.npy\n",
            "test_per_category__per_subj__1.npy  validation_set__per_subj__1.npy\n",
            "test_per_category__per_subj__3.npy  validation_set__per_subj__3.npy\n",
            "test_per_category__per_subj__4.npy  validation_set__per_subj__4.npy\n",
            "test_per_category__per_subj__5.npy  validation_set__per_subj__5.npy\n",
            "train_set__per_subj__1.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### model_1 on test_5"
      ],
      "metadata": {
        "id": "4rG-D6Ib_Kik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r gdrive/MyDrive/your_path/pBCI_models_per_subj/per_subj_split_1/models .\n",
        "!ls -l models\n",
        "#for now config per subject, so change the subject number to be 1\n",
        "!python -u SpecklesAI/inference_and_eval.py --use_per_subj_config --num_of_chunks_to_aggregate 25 --read_stored_dataset  --test_set_per_category_file test_per_category__per_subj__5.npy --split_num 1"
      ],
      "metadata": {
        "id": "aws5gA91_OqD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye0mqNbV5fuf"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models"
      ],
      "metadata": {
        "id": "G5Sm5vCXLK4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHs8YdR7qi6v"
      },
      "source": [
        "## sample subj"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp gdrive/MyDrive/your_path/data_exp3_prep_BCI/per_subj_splits/*_5.npy .\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3oNbGpBEsRU",
        "outputId": "8373dc10-d768-4fb7-bf42-09a914102b24",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\t     SpecklesAI\t\t\t\t train_set__per_subj__5.npy\n",
            "sample_data  test_per_category__per_subj__5.npy  validation_set__per_subj__5.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### morning in train/val and midday in test"
      ],
      "metadata": {
        "id": "stTkSxADJvwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# id using per subject config with a single subject, leave split_num 1\n",
        "!python -u SpecklesAI/prep_and_train_tf.py --use_per_subj_config --batch_size 4100 --epochs 170 --sz_conv 8 --num_of_chunks_to_aggregate 50 --random_seed 9  --train_set_file train_set__per_subj__5.npy --validation_set_file validation_set__per_subj__5.npy --test_set_per_category_file test_per_category__per_subj__5.npy --split_num 1  --read_stored_dataset"
      ],
      "metadata": {
        "id": "i_Y8jkKcMzmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### save model"
      ],
      "metadata": {
        "id": "sj7ZXOqVMYUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir gdrive/MyDrive/your_path/pBCI_models_per_subj/\n",
        "!mkdir gdrive/MyDrive/your_path/pBCI_models_per_subj/per_subj_split_5\n",
        "!mv models gdrive/MyDrive/your_path/pBCI_models_per_subj/per_subj_split_5/.\n",
        "!mv *.png gdrive/MyDrive/your_path/pBCI_models_per_subj/per_subj_split_5/.\n",
        "!mv *.csv gdrive/MyDrive/your_path/pBCI_models_per_subj/per_subj_split_5/.\n",
        "!ls -l gdrive/MyDrive/your_path/pBCI_models_per_subj/per_subj_split_5"
      ],
      "metadata": {
        "id": "7UmohY__MaMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTEy8URQEpny"
      },
      "source": [
        "#Inference - for comprehension\n",
        "- for first paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7w1N5p8E4BT"
      },
      "source": [
        "Inference on already trained and saved models per gen split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1r9k5GPFRKF"
      },
      "source": [
        "###Copy test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LsvkeeCFQi-"
      },
      "outputs": [],
      "source": [
        "!cp gdrive/MyDrive/your_path/data_exp3_prep/per_subj_splits/test*_*.npy .\n",
        "!ls -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGQMpSZrErZe"
      },
      "source": [
        "### sample subj1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ft_kS3jnEvXw"
      },
      "outputs": [],
      "source": [
        "!cp -r gdrive/your_path/code_and_data/p1_models_per_subj/per_subj_split_1/models .\n",
        "!ls -l models\n",
        "!python -u SpecklesAI/inference_and_eval.py --use_per_subj_config --num_of_chunks_to_aggregate 25 --read_stored_dataset  --test_set_per_category_file test_per_category__per_subj__1.npy --split_num 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2kDnwN-FCQu"
      },
      "source": [
        "### sample subj 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "javfImcsZcj1"
      },
      "outputs": [],
      "source": [
        "!cp -r gdrive/MyDrive/your_path/p1_models_per_subj/per_subj_split_2/models .\n",
        "!ls -l models\n",
        "!python -u SpecklesAI/inference_and_eval.py --use_per_subj_config --num_of_chunks_to_aggregate 25 --read_stored_dataset  --test_set_per_category_file test_per_category__per_subj__2.npy --split_num 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generalization"
      ],
      "metadata": {
        "id": "JxzqYpcIRFMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create gen split datasets"
      ],
      "metadata": {
        "id": "Xb0vrLhlRQcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -u SpecklesAI/prepare_datasets_for_all_splits.py --random_seed 9  --train_set_file train_set_split_ --validation_set_file validation_set_split_ --test_set_per_category_file test_per_category_split_"
      ],
      "metadata": {
        "id": "aCvggKX8RHyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "metadata": {
        "id": "XtkGB-NaRXIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Save"
      ],
      "metadata": {
        "id": "vea8CgfkRYAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir gdrive/MyDrive/your_path/data_exp3_prep_BCI/gen_splits\n",
        "!mv *.npy\tgdrive/MyDrive/your_path/data_exp3_prep_BCI/gen_splits/.\n",
        "!ls -l gdrive/MyDrive/your_path/data_exp3_prep_BCI/gen_splits"
      ],
      "metadata": {
        "id": "ilhr8BUORYOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "9qiR2728SB3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gen split 1\n",
        "- example"
      ],
      "metadata": {
        "id": "5SNcE_oBSDIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To copy preprecessed datasets for the current split run:\n",
        "!cp gdrive/MyDrive/your_path/data_exp3_prep_BCI/gen_splits/*_1.npy .\n",
        "\n",
        "!python -u SpecklesAI/prep_and_train_tf.py --batch_size 1000 --epochs 120 --num_of_chunks_to_aggregate 25 --random_seed 9  --train_set_file train_set_split__1.npy --validation_set_file validation_set_split__1.npy --test_set_per_category_file test_per_category_split__1.npy --split_num 1  --read_stored_dataset"
      ],
      "metadata": {
        "id": "sQ0u8luNSFst"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}